# Read: Class 42 - Pythonisms

## Dunder Methods

- In Python, special methods are a set of predefined methods you can use to enrich your classes. They are easy to recognize because they start and end with double underscores, for example **init** or **str**.

As it quickly became tiresome to say under-under-method-under-under Pythonistas adopted the term “dunder methods”, a short form of “double under.”

These “dunders” or “special methods” in Python are also sometimes called “magic methods.” But using this terminology can make them seem more complicated than they really are—at the end of the day there’s nothing “magical” about them. You should treat these methods like a normal language feature.

Dunder methods let you emulate the behavior of built-in types. For example, to get the length of a string you can call len('string'). But an empty class definition doesn’t support this behavior out of the box:

    class NoLenSupport:
        pass

    >>> obj = NoLenSupport()
    >>> len(obj)
    TypeError: "object of type 'NoLenSupport' has no len()"

To fix this, you can add a **len** dunder method to your class:

    class LenSupport:
        def __len__(self):
            return 42

    >>> obj = LenSupport()
    >>> len(obj)

Another example is slicing. You can implement a **getitem** method which allows you to use Python’s list slicing syntax: obj[start:stop].

- Right upon starting my class I already need a special method. To construct account objects from the Account class I need a constructor which in Python is the **init** dunder:

        class Account:
            """A simple account class"""

            def __init__(self, owner, amount=0):
                """
                This is the constructor that lets us create
                objects from this class
                """
                self.owner = owner
                self.amount = amount
                self._transactions = []

  The constructor takes care of setting up the object. In this case it receives the owner name, an optional start amount and defines an internal transactions list to keep track of deposits and withdrawals.

This allows us to create new accounts like this:

    >>> acc = Account('bob')  # default amount = 0
    >>> acc = Account('bob', 10)

### Cited from: https://dbader.org/blog/python-dunder-methods

## Iterators

- Over the next few paragraphs we’re going to implement a class called Repeater that can be iterated over with a for-in loop, like so:

        repeater = Repeater('Hello')
        for item in repeater:
            print(item)

  Like its name suggests, instances of this Repeater class will repeatedly return a single value when iterated over. So the above example code would print the string Hello to the console forever.

To start with the implementation we’ll define and flesh out the Repeater class first:

    class Repeater:
        def __init__(self, value):
            self.value = value

        def __iter__(self):
            return RepeaterIterator(self)

On first inspection, Repeater looks like a bog-standard Python class. But notice how it also includes the **iter** dunder method.

What’s the RepeaterIterator object we’re creating and returning from **iter**? It’s a helper class we also need to define for our for-in iteration example to work:

    class RepeaterIterator:
        def __init__(self, source):
            self.source = source

        def __next__(self):
            return self.source.value

Again, RepeaterIterator looks like a straightforward Python class, but you might want to take note of the following two things:

In the **init** method we link each RepeaterIterator instance to the Repeater object that created it. That way we can hold on to the “source” object that’s being iterated over.

In RepeaterIterator.**next**, we reach back into the “source” Repeater instance and return the value associated with it.

In this code example, Repeater and RepeaterIterator are working together to support Python’s iterator protocol. The two dunder methods we defined, **iter** and **next**, are the key to making a Python object iterable.

We’ll take a closer look at these two methods and how they work together after some hands-on experimentation with the code we’ve got so far.

Let’s confirm that this two-class setup really made Repeater objects compatible with for-in loop iteration. To do that we’ll first create an instance of Repeater that would return the string 'Hello' indefinitely:

    >>> repeater = Repeater('Hello')

And now we’re going to try iterating over this repeater object with a for-in loop. What’s going to happen when you run the following code snippet?

    >>> for item in repeater:
    ...     print(item)

Right on! You’ll see 'Hello' printed to the screen…a lot. Repeater keeps on returning the same string value, and so, this loop will never complete. Our little program is doomed to print 'Hello' to the console forever:

Hello
Hello
Hello
Hello
Hello
...
But congratulations—you just wrote a working iterator in Python and used it with a for-in loop. The loop may not terminate yet…but so far, so good!

### Cited from: https://dbader.org/blog/python-iterators

## Generators

- Let’s start by looking again at the Repeater example that I previously used to introduce the idea of iterators. It implemented a class-based iterator cycling through an infinite sequence of values.

This is what the class looked like in its second (simplified) version:

    class Repeater:
        def __init__(self, value):
            self.value = value

        def __iter__(self):
            return self

        def __next__(self):
            return self.value

If you’re thinking, “that’s quite a lot of code for such a simple iterator,” you’re absolutely right. Parts of this class seem rather formulaic, as if they would be written in exactly the same way from one class-based iterator to the next.

This is where Python’s generators enter the scene. If I rewrite this iterator class as a generator, it looks like this:

    def repeater(value):
        while True:
            yield value
    We just went from seven lines of code to three.

Not bad, eh? As you can see, generators look like regular functions but instead of using the return statement, they use yield to pass data back to the caller.

Will this new generator implementation still work the same way as our class-based iterator did? Let’s bust out the for-in loop test to find out:

    >>> for x in repeater('Hi'):
    ...    print(x)
    'Hi'
    'Hi'
    'Hi'
    'Hi'
    'Hi'
    ...

Yep! We’re still looping through our greetings forever. This much shorter generator implementation seems to perform the same way that the Repeater class did.

(Remember to hit Ctrl+C if you want out of the infinite loop in an interpreter session.)

Now, how do these generators work? They look like normal functions, but their behavior is quite different. For starters, calling a generator function doesn’t even run the function. It merely creates and returns a generator object:

    >>> repeater('Hey')
    <generator object repeater at 0x107bcdbf8>

The code in the generator function only executes when next() is called on the generator object:

      >>> generator_obj = repeater('Hey')
      >>> next(generator_obj)
      'Hey'

If you read the code of the repeater function again, it looks like the yield keyword in there somehow stops this generator function in mid-execution and then resumes it at a later point in time:

    def repeater(value):
        while True:
            yield value

And that’s quite a fitting mental model for what happens here. You see, when a return statement is invoked inside a function, it permanently passes control back to the caller of the function. When a yield is invoked, it also passes control back to the caller of the function—but it only does so temporarily.

Whereas a return statement disposes of a function’s local state, a yield statement suspends the function and retains its local state.

In practical terms, this means local variables and the execution state of the generator function are only stashed away temporarily and not thrown out completely.

Execution can be resumed at any time by calling next() on the generator:

    >>> iterator = repeater('Hi')
    >>> next(iterator)
    'Hi'
    >>> next(iterator)
    'Hi'
    >>> next(iterator)
    'Hi'

This makes generators fully compatible with the iterator protocol. For this reason, I like to think of them primarily as syntactic sugar for implementing iterators.

### Cited from: https://dbader.org/blog/python-generators

## Things I want to know more about

- I see this being very useful just going to have to take some getting used too. To understand how I can implement them into my code.

## References

- https://dbader.org/blog/python-dunder-methods
- https://dbader.org/blog/python-iterators
- https://dbader.org/blog/python-generators
- https://realpython.com/lessons/what-are-python-generators/
- https://realpython.com/primer-on-python-decorators/
